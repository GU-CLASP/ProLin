#+OPTIONS: toc:nil ':t ":t
#+LATEX_CLASS: article
#+LATEX_HEADER: %include polycode.fmt
#+LATEX_HEADER: %format !-> = "\rightarrow_{!}"
#+LATEX_HEADER: %format ?-> = "\rightarrow_{?}"
#+LATEX_HEADER: %format . = "."
#+LATEX_HEADER: %let operator = "."
#+LATEX_HEADER: \pdfpagewidth=8.5in
#+LATEX_HEADER: \pdfpageheight=11in
#+LATEX_HEADER: \usepackage{ijcai20}
#+LATEX_HEADER: \usepackage{times}
#+LATEX_HEADER: \usepackage{soul}
#+LATEX_HEADER: \usepackage{url}
# FIXME: #+LATEX_HEADER: \usepackage[hidelinks]{hyperref}
#+LATEX_HEADER: \usepackage{newunicodechar}
#+LATEX_HEADER: \input{newunicodedefs}
#+LATEX_HEADER: \usepackage{natbib}
#+LATEX_HEADER: \usepackage[utf8]{inputenc}
#+LATEX_HEADER: \usepackage[small]{caption}
#+LATEX_HEADER: \usepackage{graphicx}
#+LATEX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER: \usepackage{amsthm}
#+LATEX_HEADER: \usepackage{booktabs}
#+LATEX_HEADER: \usepackage{xcolor}
#+LATEX_HEADER: \urlstyle{same}
#+LATEX_HEADER: \usepackage{makecell}

# guidelines: https://www.ijcai.org/authors_kit

#+LATEX_HEADER: \usepackage{mathtools}
#+LATEX_HEADER: \newcommand{\ttr}[1]{\left[\begin{array}{lcl}#1\end{array}\right]}
#+LATEX_HEADER: \newcommand{\tf}[2]{\mathrm{#1} & : & \mathit{#2}\\}
#+LATEX_HEADER: \newcommand{\rf}[2]{\mathrm{#1} & = & \mathit{#2}\\}
#+LATEX_HEADER: \newcommand{\mf}[3]{\mathrm{#1=#2} & : & \mathit{#3}\\}
#+LATEX_HEADER: \newcommand{\type}[1]{$\mathit{#1}$}
#+LATEX_HEADER: \newcommand{\jg}[1]{\noindent \textcolor{blue}{\textbf{\emph{[jg:  #1]}}}}


#+TITLE: Questions and clarifications with linear logic
# Alternate title: On the role of metavariables in symbolic dialogue modelling

#+AUTHOR:

\begin{abstract}
In this paper we propose an account for dialogue coherence using Linear Logic. We focus our study on the range of things that can be potentially clarified in dialogue, and argue that they can be represented as meta-variables. 
\end{abstract}

* Introduction

KEY IDEA: meta-variable stand in for any piece of information which is left for
interpretation

* Background

** Dialogue management                                                 :Vlad:
A key aspect of dialogue systems design is the coherence of system’s
responses.  In this respect, a key component of a dialogue system is the
dialogue manager, which selects appropriate system actions depending
on the current state and the external context.

Two families of approaches to dialogue management can be considered:
hand-crafted dialogue strategies
citep:allen1995trains,larsson2002issue,jokinen2009constructive and
statistical modelling of dialogue
citep:rieser2011reinforcement,young2010hidden. Frameworks for
hand-crafted strategies range from finite-state machines and
form-filling to more complex dialogue planning and logical inference
systems. Statistical models help to contend with the uncertainty that
arises in human interaction; from noisy signals from speech
recognition and other sensors to pragmatic ambiguities.

End-to-end systems that do not specify a dialogue manager as an
explicit component have gained lots of attention recently
[[citep:roller2020recipes][e. g.,::]]. Although most of them are
focused on chit-chat dialogues, coherence plays a crucial role there
too. Typically issues of such systems are related to memory
limitations which cause repetition, contradiction and
forgetfulness. Having a policy for dialogue coherence would be
beneficial for such systems.

Although there has been a lot of development in dialogue systems in
recent years, only a few approaches reflect advancements in /dialogue
theory/. \jg{But why should we care!} Our aim is to closely integrate dialogue systems with work in
theoretical semantics and pragmatics of dialogue.

*** Information state update approach
In this work we are employing an information-state update (ISU) approach,
following
citet:traum1999model,larsson2002issue,ginzburg2012interactive. In this
view we present the information available to each participant of the
dialogue (either a human or an artificial agent) in a rich information
state. Being rich entails that the information state contains
hierarchy of facts, including the ones that are thought to be shared
and the ones that have not been yet publicised.[fn::TBD consider if we need this] As an illustration citet:ginzburg2012interactive expresses the information state of a dialogue system,
in TTR notation.
\begin{equation}
\def\arraystretch{1.5}
\setlength{\arraycolsep}{1pt}
\ttr{
\rf{private}{\ttr{\rf{tt_1}{TT(Bus52,0,Sko,Got)}
                  \rf{tt_2}{TT(Bus18,1,Joh,Got)}}}
\rf{public}{\ttr{\rf{LU}{Ask(U,Question(\lambda t.TT(b,t,d,Got)))}
                 \rf{QUD}{set()}}}}
\end{equation}

What is expressed here is that dialogue system was just asked (in the
field public.LU -- latest utterance) by a user ($U$) a question like
‘When is there a bus from Gotaplatsen’ (the underspecified[fn::TBD
more about underspecification] variables $b$, $t$ and $d$ correspond
to bus number, time and destination respectively). This information is
/public/[fn::Later on, following citet:ginzburg2015understanding we will
denote the public part of the information state as Dialogue Gameboard
(DGB).] and available to a user as well. What is private is the
knowledge of the timetable ($TT$) available to the system and not yet
made public, hence it is stored in the /private/ part of the information
state.

Let’s now consider the /update/, another essential component of ISU. In
this case, we will rely on a set of rules, that will govern the
updates. citet:ginzburg2012interactive defines one of the most basic
rules -- the rule of QUD-incrementation -- the procedure of updating
the current set of questions under discussions (QUD) if the latest
utterance (LU) is a question. This operation is salient to a user and
therefore it constitutes the update of the public part of the
information state.

#+BEGIN_code
if public.LU = Ask(U, Question(x)):
    push Question(x) into public.QUD
#+END_code
The updated state will look as follows:
\begin{equation}
\def\arraystretch{1.5}
\setlength{\arraycolsep}{1pt}
\ttr{
\rf{private}{\ttr{\rf{tt_1}{TT(Bus52,0,Sko,Göt)}
                  \rf{tt_2}{TT(Bus18,1,Joh,Göt)}}}
\rf{public}{\ttr{\rf{LU}{Ask(U,Question(\lambda t.TT(b,t,d,Got)))}
              \rf{QUD}{set(Question(\lambda t.TT(b,t,d,Got))}}}}
\end{equation}

The main benefit of using rich representation of information state
with underspecified components is to be able to address wide range of
clarifications from both parties. This is especially beneficial in
case of automatic speech recognition or natural language understanding
errors. But even put the errors aside, we can also consider topically
relevant follow-up questions by the system, e.g. `What bus?', or
contributions when user provides more information than they were
asked, e.g. `Bus 18 to Skogome'.
 
*** COMMENT KoS
TODO: we are not implementing Kos here, just use something from it


KoS (not an acronym) citep:ginzburg2012interactive provides among the
most detailed theoretical treatments of domain general conversational
relevance citep:ginzburg2012interactive, especially for query
responses---see citet:purver-rlc06 on Clarification Requests,
citet:lupkowski2017query for a general account---and this ties into
the KoS treatment of non sentential utterances, again a domain crucial
for naturalistic dialogue systems and where KoS has among the most
detailed analyses citep:fgl07,ginzburg2012interactive.[fn::TBD DS/TTR,
incrementality?]

In KoS (and other dynamic approaches to meaning), language is compared
to a game, containing players (interlocutors), goals and rules. KoS
represent language interaction by representing the dynamically
changing context. The meaning of an utterance is how it changes the
context. Compared to most approaches
[[citep:roberts2012information][e.g.::]], which represent a single context
for both dialogue participants), KoS keeps a separate representation
for each participant, using the /Dialogue Game Board/
(DGB). DGBs represent the information states of the participants, and
comprise a private part and the dialogue gameboard that represents
information arising from publicized interactions. It tracks, at the
very least, shared assumptions/visual space, moves (= utterances, form
and content), and questions under discussion.

KoS is based on the formalism of Type Theory with Records (TTR). There
has been a wide range of work in this formalism which includes the
modelling of intentionality and mental attitudes citep:cooper-rlc,
generalised quantifiers citep:cooper-gq13, co-predication and dot
types in lexical innovation, frame semantics for temporal reasoning,
reasoning in hypothetical contexts citep:cooper-lacl11, spatial
reasoning citep:dobnik2017interfacing, enthymematic reasoning
citep:ellen-aisb, clarification requests
citep:purver-rlc06,ginzburg2012interactive, negation
citep:cooper2012negative, non-sentential utterance resolution
citep:fgl07,ginzburg2012interactive and iconic gesture
citep:lucking16.

** Clarification requests                                                :Vlad:
- what are CRs
- why do they exist?
- how frequent are they?
- what gets clarified
- why it is crucial for SDS: 
  - why fine-grained
  - user responses with open vocabulary ASR 

** Proof search as a programming language

The prevailing tradition in formal semantics (TODO:citations) is to
represent (declarative) statements as propositions, formalized in an
underlying logic (often first-order logic).

In particular, in linguistic theories based on intuitionistic logic
(such as TTR), true statements corresponds to propositions which admit
a proof.

There is a long history (TODO:cite prolog seminal paper?) of using
proof search as a declarative programming paradigm.  In the most
abstract sense, the programmer specifies /axioms/ and /rules of inference/
which model their application domain. Typically such a system of
axioms and rules represents a database of facts. For example, the
axiom |(Leave 55 Gotaplatsen 11.50)| can model the fact that bus 55
leaves from Götaplatsen at 11:50. The rule |(Leave x Gotaplatsen y ->
Arrive x CentralStationen (y+0.75))| can represent travelling times on
a certain line.

Then, the user may define a query (or goal) as
a logical formula. The system can then search for a proof of a goal as a
way to query the database of facts. In the most useful cases, goals
contain /metavariables/[fn::here, we use the convention that metavariables are lowercase letters.]. For example, the goal |(Leave x
Götaplatsen y)| corresponds to a request to list all the buses leaving
from Götaplatsen (as |x|) together with their departure time (as |y|).


*** Linear logic
Typically, and in particular in the archetypal logic programming
language prolog (TODO citation), axioms and rules are expressed within the general
framework of first order logic. However, several authors
citep:dixon2009plans,martens2015programming have proposed to use
linear logic citep:girard1995linear instead. For our purpose, the
crucial feature of linear logic is that facts may be used /only
once/. For example, one could have a rule |IsAt x Gotaplatsen y ⊸ IsAt x
CentralStationen (y+0.75)|. Consequently, after firing the above rule,
the premiss |(Is x Gotaplatsen y)| becomes unavailable for any other rule.
Thereby the linear arrow |⊸| can be used to conveniently model that a
bus cannot be at two places simultaneously.

Thus, the hypotheses available for proof search correspond to the
/state/ of the system. In our application they will correspond to the
/information state/ of the dialog participant.

This way, the firing of a linear rule corresponds to an /action/ of an
agent, and a complete proof corresponds to a /scenario/, i.e. a sequence
of actions, possibly involving action from several agents.  However,
the information state (typically in the literature and in this paper
as well), corresponds to the state of a /single/ agent. Thus, a
scenario is concieved as a sequence of actions and updates of the
information state of a single agent $a$, even though such actions can be
attributed to any other dialogue participant $b$. (That is, they are $a$'s representation of actions of $b$.) 
Scenarii can be realised
as a sequence of actual actions and updates. That is, an action can
result in sending a message to the outside world (in the form of
speech, movement, etc.). Conversely, events happening in the outside
world can result in updates of the information state (through a model of the
perceptory subsystem).

In an actual dialogue, the scenario is therefore suspended between
every interaction, and the state represents the current mental state
of the agent which is modelled.[fn::possibly remove this sentence]

#+BEGIN_code
TODO: import example from later
#+END_code

It is important to note that we will not forego the unrestricted
(i.e. non-linear) implication (|->|). Rather, both implications will
co-exist in our implementation, thus we can represent simultaneously
transient facts, or states, (introduced by the linear arrow) and
immutable facts (introduced by the unrestricted arrow).

*** Metavariables and unification

In prolog-like languages, metavariables play the role of unknowns,
whose value can become fixed for a goal to be reached.

In the context of linear-logic proof search, this means that, at any
point in the scenario, state can refer to metavariables.

#+BEGIN_code
TODO: import example from later
#+END_code

In this situation, metavariables represent a certain amount of
flexibility in the scenario: /so far/ the scenario works for any value
which could be assigned to the metavariable. In this paper we explore
the potential of using metavariables in this context.

* Theory and running example

** Question-answering with metavariables

A first use for metavariables is to represent the requested answer of a question.

In this paper, we represent a question by a predicate P over a type A. That is, using a typed intuitionistic logic:
#+BEGIN_code
A  : Type
P  : A  -> Prop
#+END_code

The intent of the question is to find out about a value $x$ of type
$A$ which makes $P x$ true. We show several examples in table
ref:tbl:qa-ex.  It is worth stressing that the type $A$ can be large
(for example asking for any location) or as small as a boolean (if one
requires a simple yes/no answer).  We note in passing that, typically,
yes/no questions can be answered not just by a boolean but by
qualifing the predicate in question (Table ref:tbl:qa-ex, last two
rows).  In this instance |A = Prop -> Prop|. (Also, a simple "no"
answer can be ambiguous when the question is negative.)


\begin{table*}[htbp]
\begin{tabular}{lllll}
utterance & A & P & a\\
\hline
Where does John live?    & |Location    | & |\x.Live John x                          | & in London & |ShortAnswer London Location| \\
Does John live in paris? & |Bool        | & \makecell{|\x.if x then (Live John Paris)| \\ |else Not (Live John Paris)|} & yes & |ShortAnswer True Bool| \\
What time is it?         & |Time        | & |\x.IsTime x                             | & It is 5am. & |Assert (IsTime 5.00)| \\
Does John live in paris? & |Prop -> Prop| & |\m. m (Live John Paris)                 | & yes & |ShortAnswer (\x. x)  (Prop -> Prop)| \\
Does John live in paris? & |Prop -> Prop| & |\m. m (Live John Paris)                 | & from January & \makecell{|ShortAnswer (\x. FromJanuary(x))|\\|(Prop -> Prop)|} \\
\end{tabular}
\caption{Examples of questions and the possible corresponding answers.\label{tbl:qa-ex}}
\end{table*}

Within the state of the agent, if the value of the requested answer is
represented as a metavariable |x|, then the question can be represented as: |Q A x (P x)|.

That is, the pending question is a triple of a type, a
metavariable |x|, and a proposition where |x| occurs.

We stress that |P x| is /not/ part of the information state of the
agent yet, rather the fact that the above question is /under
discussion/ is a fact. For example, after asking "when does John
live", we'd have:

#+BEGIN_code
haveQud : QUD (Q Location x (Live John x))
#+END_code

Resolving a question can be done by communicating an answer. An answer
to a question |(A : Type; P : A -> Prop)| can be of either of the two following forms: 
- ShortAnswer :: is a pair of an element |X:A| and its type |A|, represented as |ShortAnswer X A|
- Assertion :: is a proposition |P|, represented as |Assert P|



Therefore, one way to process a short answer is by the |processShort| rule:

#+BEGIN_code
processShort : ∀ x a p. ShortAnswer x a
             ⊸ QUD (Q x a p) ⊸ p
#+END_code

We demand in particular that types in the answer and in the question
match (|a| occurs in both places). Additionally, because |x| occurs in |p|, the information
state will mention the concrete |x| which was provided in the answer.

TODO: example

To process assertions, we can use the following rule:

#+BEGIN_code
processAssert : ∀ x a p. Assert p
              ⊸ QUD (Q x a p) ⊸ p
#+END_code

That is, (1) if it was asserted |p|, (2) the proposition |q| is part of a question under discussion, and (3) p can be
unified with q, then the assertion resolves the
question. Additionally, the metavariable |x| is grounded to a concrete
value by virtue of unification of |p| and |q|. Examples:

"John lives in Paris" answers both questions "Where does John live"
and "Does John live in Paris" (there is unification), but, not, for
example "What time is it?" (there is no unification).

TODO: in both cases (processAssert and processShort) correspond to updates of the information state.

*** A bit more on polar questions
Treatment of "no":
#+BEGIN_code
"does john live in paris?"
⟦q⟧  = [A = Prop -> Prop;
       P = \m. m (Live John Paris)]
"doesn't john live in paris?
⟦q'⟧ = [A = Prop -> Prop;
       P = \m. m (Not (Live John Paris))]
"no"/"oui"
⟦a⟧  = ShortAnswer (\x.if (Not y) then (Not y) else (Not y)) (Prop -> Prop)
"si"
⟦a'⟧ = ShortAnswer (\x.if (Not y) then y) (Prop -> Prop)
#+END_code

More on ellipsis?
- "he doesn't" 
- "he does"




** Notion of unique and concrete answers

However, one would consider the question resolved only if the answer
is "unique". For example, the assertion "John lives somewhere" does
not resolve the question "where does John live". That is, if
"somewhere" is represented by a metavariable, then the answer is not
resolving.

Assume a two-place predicate |Eat| with agent as first argument and
object as second argument. The phrase "John eats an apple" could then
be represented as |Eat(John,Apple)|. According to our theory, one can
then represent the phrase "John eats" as |Eat(John,x)|, with |x| being
a metavariable.

Assume now a system with the state:

#+BEGIN_code
Eat(John,Apple)
#+END_code

Then the question "What does John eat", represented as |(Q Food x
(Eat(John,x)))|, can be answered.  From the point of view of modelling
with linear logic, we could attempt to model the answering by the
rule:

#+BEGIN_code
(a : Type) -> (x : a) -> (p : Prop)
-> QUD (Q a x p) -> p ⊸ (p ⊗ Answer x (Q x p))
#+END_code


The above states that, if |x| makes the proposition |p| true (more
precisely, provable --- we require that |p| is a fact in the last
argument) then it is valid to answer |x| if |Q a x p| is under
discussion. However, there is an issue with the above rule: if |x| is
/not unique/, then one would not consider $x$ a suitable
answer. Indeed, assume instead that the system is in the state:

#+BEGIN_code
Eat(John,x)
#+END_code

Then the question cannot be answered, because |x| stands for some
unknown thing. The proper answer is then "I do not know".

Hence, we introduce another type-former |(x : A) !-> B|. As for |(x :
A) -> B|, it introduces the metavariable $x$. However, the rule fires
only when |x| is made /ground/ (it is bound to a term which does not
contain any metavariable) and /unique/ by matching the rule. That is,
it won't match in the previous example, because the answer is not
ground (it contains unknowns). Additionally, it won't match if the
state of the system is composed of the two
hypotheses |Eat(John,Apple)| and |Eat(John,Orange)|: the answer is not
unique.

Thus, the rule for answering can be written:

#+BEGIN_code
produceAnswer : (a : Type) -> (x : a) !-> (p : Prop)
-> QUD (Q a x p) -> p ⊸ (p ⊗ ShortAnswer x a)
#+END_code

For example, if we have the following state:
#+BEGIN_code
QUD (Q Food x (Eat(John,x)))
Eat(John,Apple)
#+END_code

The system can unify |QUD (Q Food x (Eat(John,x)))| and |QUD (Q a x
p)|, yielding |a = Food|, |p=Eat(John,x)|. Then, we search for a
proof |p|, and to do this, it can unify |Eat(John,x)|
with |Eat(John,Apple)|, giving finally the answer |x=Apple| and
therefore the state becomes:
#+BEGIN_code
Eat(John,Apple)
ShortAnswer Apple Food
#+END_code

Note that the fact |Eat(John,Apple)| is found both as hypothesis and a
conclusion of |produceAnswer|, and therefore it is remains in the
information state.

** Clarification requests

In this section we discuss an alternative kind of answering, which is
to issue clarification requests.  To see how they can occur, consider
again the question "what does john eat", in the same information state
as above.
A proper answer could be "An apple and an orange" or "An apple or an
orange". However we consider here a third possibility: instead of
answering, the agent can issue a clarification request (TODO: is this
reasonable? When ... etc.) [fn:VM: maybe more intuitive example, e.g. with ’like’? like(john,bananas) like(john,dogs)]

To illustrate, consider the question "What is being eaten?"
represented as |Q x (Eat(y,x))|,  with the state
#+BEGIN_code
Eat(John,Apple)
Eat(Mary,Apple)
#+END_code
Then the agent can unambguously answer "An apple": even if we do not
know who we're talking about, it does not matter: only an apple is
being eaten. However, If the state is
#+BEGIN_code
Eat(John,Apple)
Eat(Mary,Orange)
#+END_code
Then, a probable answer would be a /clarification request/, namely
"eaten by whom?".

To detect situations where a clarification request can be issued, we can use the following rule:
#+BEGIN_code
(a : Type) -> (x : a) ?-> (p : Prop)
   -> QUD (Q x p) -> p ⊸ (p ⊗ CR)
#+END_code

The conditions are similar to that of the answering rule. The
principal difference is the use of the |?->| operator, which conditions
on a metavariable which remains not (fully) ground, or which can be
unified to several ground terms --- the opposite of the |!->| operator.

We can then turn our attention to the formulation of this clarification request.
It is itself a question, and has a tricky representation:

#+BEGIN_code
Q Person z (z = y)
#+END_code

That is, the question is asking about some aspect which was left
implicit in the original question (what is being eaten). In our terms,
it must refer to the metavariable (|y|) which the original
question included.  After getting an answer, (say |Mary|), |z|
will be bound to a ground term, and, in turn, the fact |z=y| will
ensure that |y| becomes ground. 

#+BEGIN_code
Eat(John,Apple)
Eat(Mary,Orange)
ori :: QUD (Q Food x (Eat(y,x)))
cr ::  QUD (Q Person z (z=y))
a  ::  ShortAnswer Mary Person
#+END_code
after applying |processShort|:
#+BEGIN_code
Eat(John,Apple)
Eat(Mary,Orange)
ori :: QUD (Q Food x (Eat(y,x)))
r ::  Mary=y
#+END_code


This means the original question will,
by unification, become |Q Food x (Eat(Mary,x))|, and it can be
unambiguously answered using the /canAnswer/ rule. We note that the
logical form of the question (|z| such that |z=y|) is typically
realised in a complicated way. In our example, it could be "eaten by
whom"; echoing part of the original question and assuming cooperative
communication so that the questioner properly relates the
clarification request to the implicits of the original questions. (In
sec. ref:sec:bus)

In practice, the form of clarification questions will greatly vary
depending on the context.

The above suposes a clear-cut distinction: if an answer is unique, it
is given; otherwise a clarification request is issued. However,
answers could simply be exhaustive ("An apple or an orange").  If the
original questioners are unhappy with the ambiguity, they are free to
issue more precise questions. In practice, one can easily imagine an
ambiguity threshold after which clarification requests are
preferred. In the simplest form, this ambiguity threshold could be
expressed by the length of the answer. In our example, if one has to
list, say, 20 different kinds of food, it is easy to imagine that the
answer won't be fully given. In fact, this question can be the topic
of an experimental study.

*** TODO more CRs                                        :JP:

Consider the exchange:

#+BEGIN_quote
Where does John live?
Do you mean while he is in confinement?
#+END_quote

In the above, there is an (implicit) extra argument to the |Live|
predicate, corresponding to, say, a time
interval: |Live(who,location,confinement)|.

However most of the time one may choose to leave this parameter
implicit. This is what is done for example when asking the above
question:

#+BEGIN_code
Q Location x Live(John,x,y)
#+END_code

assuming a metavariable y of type |Bool|.

If the question can be answered without regard for whether there is
confinement or not, then the metavariable will remain free for the
duration of the dialogue. If on the other hand, answering the question
demands clarification, this can be done using the mechanisms described
above.

In sum, in our model, to support clarification requests, a system must
integrate many arguments and use metavariables.

** TODO COMMENT Extras
Merge vocabulary/citations into the previous sections.


In the linear logic implementation we treat the information /state as a
set [?] of /resources/ that can be queried and/or used. This is the
basic set of operators that constitute our implementation and that
makes it different from cite:dixon2009plans. [fn::TBD examples for each]
- Query (~X -* Y~) :: the resource ~X~ is queried and if the result is
  positive the resource ~Y~ is produced.
- Query for uniqueness (~X !-> Y~) :: the resource ~X~ is queried for
  uniqueness and if the result is positive the resource ~Y~ is produced.
- Linear implication (~X ⊸ Y~) :: the resource ~X~ is queried and if the
  result is possible, ~X~ is consumed and the resource ~Y~ is
  produced.
- Conjunction of the results (~[_:: X; _:: Y]~) :: this is a way to produce
  both ~X~ and ~Y~ as the result of applying the given rule.

As an example, we can show how the rule for /QUD-incrementation/ from
citet:ginzburg2015understanding can be formulated in this terms. Here
we consider the dialogue between interlocutors /A/ and /B/, when /A/ asks
/B/[fn::Here we omit addressees as the conversation is only two-party.]
a question /Q/. The question /Q/ just have been posed and therefore has
appeared on the DGBs of both /A/ and /B/ as the latest ~Ask~ move
(~LatestMove~).
#+BEGIN_SRC sh :exports code
-- context
_ :: DGB A (LatestMove (Ask A Q));
_ :: DGB B (LatestMove (Ask A Q));
#+END_SRC

Now we can define our update rule that act on the contextual resources:
#+BEGIN_SRC
_ : (q : Question) -> (x y : User) ->
    DGB x (LatestMove (Ask y q)) ⊸ DGB x (QUD q);
#+END_SRC
Here, for any interlocutor, her ~LatestMove~ asking a question is
consumed and her ~QUD~ is updated with the question from the ~Ask~ move.

* Application: Bus example
label:sec:bus
- Formalisation of all the aspects of the the example in the theory.
- Say it's a complete and implemented system
* Evaluation/Discussion/Future work
- discussing the corrections
- discuss the clarification requests in a more specific way: we can always redefine the referent
- in dialogue systems meta-variables are always subject to clarification and correction (substitution)
- dependencies between questions (who killed bill -> who was around?)

- clarification could be narrowing from general types to subtypes.

* References :ignore:
bibliographystyle:named
bibliography:lacatoda.bib
