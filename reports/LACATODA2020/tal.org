#+OPTIONS: toc:nil ':t ":t 
#+LATEX_CLASS: article-hermes_french
#+LATEX_HEADER: \usepackage[labelfont=bf,textfont=it,labelsep=period,justification=raggedright,singlelinecheck=false]{caption}

#+LATEX_HEADER: %include polycode.fmt
#+LATEX_HEADER: %format -* = "\rightarrowtriangle"
# alternative:                 -{\kern -1.3ex}*
#+LATEX_HEADER: %format !-> = "\rightarrow_{!}"
#+LATEX_HEADER: %format ?-> = "\rightarrow_{?}"
#+LATEX_HEADER: %format . = "."
#+LATEX_HEADER: %format \_ = "\_"
#+LATEX_HEADER: %let operator = "."
#+LATEX_HEADER: \usepackage{soul}
#+LATEX_HEADER: \usepackage{url}
#+LATEX_HEADER: \usepackage{newunicodechar}
#+LATEX_HEADER: \input{newunicodedefs}
# #+LATEX_HEADER: \usepackage{natbib}
# Natbib-like commands for harvard.sty:
#+LATEX_HEADER: \newcommand\citet[2][]{\ifthenelse{\equal{#1}{}}{\citeasnoun{#2}}{\citeasnoun[#1]{#2}}}
#+LATEX_HEADER: \newcommand\citep[2][]{\ifthenelse{\equal{#1}{}}{\cite{#2}}{\cite[#1]{#2}}}
#+LATEX_HEADER: \usepackage[utf8]{inputenc}
#+LATEX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER: \usepackage{amsthm}
#+LATEX_HEADER: \usepackage{booktabs}
#+LATEX_HEADER: \usepackage{xcolor}
#+LATEX_HEADER: \urlstyle{same}
#+LATEX_HEADER: \usepackage{makecell}
#+LATEX_HEADER: \usepackage{rotating}

#+LATEX_HEADER: \usepackage{mathtools}
#+LATEX_HEADER: \newcommand{\ttr}[1]{\left[\begin{array}{lcl}#1\end{array}\right]}
#+LATEX_HEADER: \newcommand{\tf}[2]{\mathrm{#1} & : & \mathit{#2}\\}
#+LATEX_HEADER: \newcommand{\rf}[2]{\mathrm{#1} & = & \mathit{#2}\\}
#+LATEX_HEADER: \newcommand{\mf}[3]{\mathrm{#1=#2} & : & \mathit{#3}\\}
#+LATEX_HEADER: \newcommand{\type}[1]{$\mathit{#1}$}
#+LATEX_HEADER: \newcommand{\jg}[1]{\noindent \textcolor{blue}{\textbf{\emph{[jg:  #1]}}}}
#+LATEX_HEADER: \usepackage{tikz}
#+LATEX_HEADER: \usetikzlibrary{shapes,arrows,positioning,fit}
#+LATEX_HEADER: \tikzstyle{block} = [draw, rectangle, minimum height=3em, minimum width=3em]
#+LATEX_HEADER: \tikzstyle{virtual} = [coordinate]
#+LATEX_HEADER: \usepackage{wasysym}

#+TITLE: Linear logic, metavariables and Q/A

#+SUBTITLE: \title[linear logic, metavariables and Q/A]{Dialogue management with linear logic: the role of metavariables in questions and clarifications}
#+AUTHOR: Anonymous
#+latex_header: \input{tal-preamble.tex}


* Introduction
A key aspect of dialogue systems design is the coherence of system’s
responses.  In this respect, a key component of a dialogue system is
the dialogue manager, which selects appropriate system actions
depending on the current state and the external context.

Two families of approaches to dialogue management can be considered:
hand-crafted dialogue strategies
cite:allen1995trains,larsson2002issue,jokinen2009constructive and
statistical modelling of dialogue
cite:rieser2011reinforcement,young2010hidden,williams2017hybrid. Frameworks
for hand-crafted strategies range from finite-state machines and
form-filling to more complex dialogue planning and logical inference
systems, such as Information State Update (ISU) cite:larsson2002issue
that we employ here. Statistical models help to contend with the
uncertainty that arises in human interaction; from noisy signals from
speech recognition and other sensors to pragmatic ambiguities.

End-to-end systems that do not specify a dialogue manager as an
explicit component have gained lots of attention recently (e.g.,
cite:roller2020recipes). Although most of them are focused on
chit-chat dialogues, coherence plays a crucial role there
too. Typically the main issues associated with such systems are
related to memory limitations which cause repetition, contradiction
and forgetfulness. Having a policy for dialogue coherence would be
beneficial for such systems.

Although there has been a lot of development in dialogue systems in
recent years, only a few approaches reflect advancements in /dialogue
theory/. Our aim is to closely integrate dialogue systems with work in
theoretical semantics and pragmatics of dialogue. This field has
provided accounts for linguistic phenomena intrinsic to dialogue such
as non-sentential utterances
cite:schlangen-diss,fgl07,ginzburg2012interactive, clarification
requests cite:purver-rlc06,ginzburg2012interactive and self-repair
cite:gfs-sp,houghpurver-disfl, where the resolution is intuitively
tied to the coherence of what is being said. 


To this end, a formal and in particular a logical representation is
instrumental.  This paper is concerned with the representation of
participant states and transitions in a unified logical framework.

# Identify a gap.

Even though the progress in bridging dialogue management and
theoretical research of dialogue is promising, we believe that it is
crucial to use formal tools which are most appropriate for the task:
one should be able to express the rules of various genres of dialogue in
a concise way, free, to any possible extent, of irrelevant technical
details.

In the view of citet:dixon2009plans this is best done by
representing the information-state of the agents as updatable sets of
propositions. Subsets of propositions in the information state can be
treated independently, and, therefore, a suitable and flexible way to
represent updates is as propositions in linear logic. We adopt this
view here, and further argue for it in the body of the paper.

We further extend citet:dixon2009plans framework to deal with
unclarity and ambiguity. Indeed, asking a question is typically not
done in one utterance which leaves nothing to interpretation. Rather,
an initial short and possbily ambiguous question is posed. If the
answerer deems the question unclear, a dialogue will ensue before the
question is finally resolved. In technical terms we propose to deal
with question-answering and clarification requests in the context of
dialogue management.

# How we plan to fill this gap?

To deal with such ambiguity and unclarity, we propose here the use of
/metavariables/, thereby leveraging much research on unification and
proof search in various logical frameworks.  That is, meta-variables
will stand in for any piece of information which is left to further
interpretation. In particular, in this paper we explore the potential
of using metavariables in the representation of question/answering
exchanges.

By using well-known techniques which correspond well with the
intuition of information-state based dialogue management, we are able
to provide a fully working prototype of the components of our
framework:

1. a proof-search engine based on linear logic, modified to support
   inputs from external systems (representing inputs and outputs of
   the agent)

2. a set of rules which function as a core framework for dialogue
   management (in the style of KoS cite:ginzburg2012interactive)

3. several examples which use the above to construct potential
   applications of the system.

The rest of the paper is structured as follows. In section
ref:sec:background we review important background for formalisation
and implementation theories: dialogue management, linear logic and
proof search. In section ref:sec:qa&cr we expose a treatment of
question, answers and clarification using the aforementioned
formalisms. This treatment ignores part of the dialogue management
complexities, which we address in section ref:sec:dm. We discuss
related work in ref:sec:related. Concluding remarks are provided in
ref:sec:discussion.



* Background
label:sec:background
** Dialogue management

*** KoS
KoS (not an acronym but loosely corresponds to Conversation Oriented
Semantics) cite:ginzburg2012interactive provides one of the most
detailed theoretical treatments of domain-general conversational
relevance, especially for query responses---see the work of
citet:purver-rlc06 on Clarification Requests, and
cite:lupkowski2017query for a general account---and this ties into the
KoS treatment of non sentential utterances, again a domain crucial for
naturalistic dialogue systems and where KoS has among the most
detailed analyses cite:fgl07,ginzburg2012interactive.

In KoS (and other dynamic approaches to meaning), language is compared
to a game, containing players (interlocutors), goals and rules. KoS
represents language interaction by a dynamically changing context. The
meaning of an utterance is then how it changes the context. Compared
to most approaches (e.g. cite:roberts2012information), which represent
a single context for both dialogue participants), KoS keeps separate
representations for each participant, using the /Dialogue Game Board/
(DGB). Thus, the information states of the participants comprise a
private part and the dialogue gameboard that represents information
arising from publicized interactions. The DGB tracks, at the very
least, shared assumptions/visual space, moves (= utterances, form and
content), and questions under discussion.

KoS is based on Cooper's formalism, Type Theory with Records (TTR). There
has been a wide range of work on top of this formalism, including the
modelling of intentionality and mental attitudes cite:cooper-rlc,
generalised quantifiers cite:cooper-gq13, co-predication and dot types
in lexical innovation, frame semantics for temporal reasoning,
reasoning in hypothetical contexts cite:cooper-lacl11, spatial
reasoning cite:dobnik2017interfacing, enthymematic reasoning
cite:ellen-aisb, clarification requests
cite:purver-rlc06,ginzburg2012interactive, negation
cite:cooper2012negative, non-sentential utterance resolution
cite:fgl07,ginzburg2012interactive and iconic gesture cite:lucking16.

*** Information state update approach
In this work we are employing an information-state update (ISU)
approach, following several authors, including citet:traum1999model,
citet:larsson2002issue, and citet:ginzburg2012interactive. In this
view we present the information available to each participant of the
dialogue (either a human or an artificial agent) in a rich information
state. Being rich entails that the information state contains a
hierarchy of facts, including the ones that are thought to be shared
and the ones that have not been yet publicised.

Let’s now consider the /update/, another essential component of ISU. In
this case, we will rely on a set of rules, that will govern the
updates. For instance, citet:ginzburg2012interactive defines one of
the most basic rules -- the rule of QUD-incrementation -- the
procedure of updating the current set of questions under discussions
(|QUD|) if the latest utterance is a question. This operation is
salient to a user and therefore it constitutes the update of the
public part of the information state.

# #+BEGIN_code
# if public.LU = Ask(U, Question(x)):
#     push Question(x) into public.QUD
# #+END_code

The main benefit of using a rich representation of the information
state with underspecified components is to be able to address a wide
range of clarifications from both parties. This is especially
beneficial in the case of automatic speech recognition or natural
language understanding errors. But even putting such errors aside, we
can also consider topically relevant follow-up questions by the
system, e.g. "What bus?", or contributions when the user provides more
information than they were asked, e.g. answering "Bus 18 to Skogome"
(destination is provided as well).
 
*** TODO Questions and clarifications
TODO: Questions and CRs

# CRs:
# - what are CRs -- signals of non-understanding
# - there are also side sequences, but the boundaries are somewhat blurred
# - how frequent are they?
# - what gets clarified

For spoken dialogue systems it is crucial to be able to produce and
process clarifications requests. In the case of the low confidence of
speech recognition and NLU, system can clarify its input with the
user. It is important to allow user initiative in the occasion when
user does not understand some information provided by the system. With
recent advancements in speech recognition and overwhelming preference
for open-vocabulary ASR and statistical NLU, systems provide more
opportunities for user initiative, which therefore should be
supported.

** Proof search as a programming language

The prevailing tradition in formal semantics, including in most pieces
of work cited above, is to represent (declarative) statements as
propositions, formalized in an underlying logic (often first-order
logic).

In particular, in linguistic theories based on intuitionistic logic
(such as TTR), true statements corresponds to propositions which admit
a proof.

There is a long history  of using
proof search as a declarative programming paradigm.  In the most
abstract sense, the programmer specifies /axioms/ and /rules of inference/
which model their application domain. Typically such a system of
axioms and rules represents a database of facts. For example, the
axiom |(Leave 55 Gotaplatsen 11.50)| can model the fact that bus 55
leaves from Götaplatsen at 11:50. The rule |(Leave x Gotaplatsen y ->
Arrive x CentralStationen (y+0.75))| can represent travelling times on
a certain line. 

Then, the user may define a query (or goal) as a logical formula. The
system can then search for a proof of a goal as a way to query the
database of facts. In the most useful cases, goals contain
/metavariables/[fn::here, we use the convention that metavariables are
lowercase letters.]. For example, the goal |(Leave x Gotaplatsen y)|
corresponds to a request to list all the buses leaving from
Götaplatsen (as |x|) together with their departure time (as |y|).

Because statements are propositions, it is only natural to use
proof-search as a means to represent possible moves in dialogue seen as
a game cite:larsson2000godis.


** Linear logic as a Dialogue Management Framework
Typically, and in particular in the archetypal logic programming
language prolog cite:bratko2001prolog, axioms and rules are expressed
within the general framework of first order logic. However, several
authors cite:dixon2009plans,martens2015programming have proposed to
use linear logic cite:girard1995linear instead. For our purpose, the
crucial feature of linear logic is that hypotheses may be used /only
once/. For example, one could have a rule |IsAt x Gotaplatsen y ⊸ IsAt
x CentralStationen (y+0.75)|. Consequently, after firing the above
rule, the premiss |(Is x Gotaplatsen y)| becomes unavailable for any
other rule.  Thereby the linear arrow |⊸| can be used to conveniently
model that a bus cannot be at two places simultaneously.

In general, the linear arrow corresponds to /destructive state
updates/. Thus, the hypotheses available for proof search correspond
to the /state/ of the system. In our application they will correspond
to the /information state/ of the dialogue participant.

We note that in linear logic, facts (or hypotheses) do not come in a
hierarchy. Either we have a fact, or we don't. However, in second
order variants of intuitionistic logic, like the one we use, one can
conveniently wrap propositions in constructors, to indicate that they
come with a qualification. For example, we can write |Unsure P| to
indicate that the proposition |P| may hold (for example if
clarification is required).

This way, firing a linear rule corresponds to triggering an /action/ of an
agent, and a complete proof corresponds to a /scenario/, i.e. a sequence
of actions, possibly involving action from several agents.  However,
the information state (typically in the literature and in this paper
as well), corresponds to the state of a /single/ agent. Thus, a scenario
is conceived as a sequence of actions and updates of the information
state of a single agent $a$, even though such actions can be
attributed to any other dialogue participant $b$. (That is, they are
$a$'s representation of actions of $b$.)  Scenarios can be realised as
a sequence of actual actions and updates. That is, an action can
result in sending a message to the outside world (in the form of
speech, movement, etc.). Conversely, events happening in the outside
world can result in updates of the information state (through a model
of the perceptory subsystem).

In an actual dialogue, the scenario is therefore suspended between
every interaction, and the state represents the current mental state
of the agent which is modelled.

Therefore, in our implementation, we treat the information state as a
multiset of /linear hypotheses/ that can be queried. Because they are
linear, these hypotheses can also be removed from the state, as we
discuss in detail in section ref:sec:dm.

It is important to note that we will not forego the unrestricted
(i.e. non-linear) implication (|->|). Rather, both implications will
co-exist in our implementation, thus we can represent simultaneously
transient facts, or states, (introduced by the linear arrow) and
immutable facts (introduced by the unrestricted arrow).

*** Transition rules

In particular, we have a fixed set of rules (they remain available
even after being used). Each such rule manipulates a part of the
information state (captured by its premisses) and leaves everything
else in the state alone.



* Questions and clarifications
label:sec:qa&cr
** Question-answering with metavariables
In prolog-like languages, metavariables play the role of unknowns,
whose value can become fixed for a goal to be reached.
In this subsection we show how a metavariable can represent what is
being asked, as the unknown in a proposition.

A first use for metavariables is to represent the requested answer of
a question.

In this paper, we represent a question by a predicate |P| over a
type |A|. That is, using a typed intuitionistic logic:
#+BEGIN_code
A  : Type
P  : A  -> Prop
#+END_code

The intent of the question is to find out about a value |x| of
type |A| which makes |P x| true, or at least held true by the other
participant. We show several examples in table ref:tbl:qa-ex.  It is
worth stressing that the type |A| can be large (for example asking for
any location) or as small as a boolean (if one requires a simple
yes/no answer).  We note in passing that, typically, polar questions
can be answered not just by a boolean but by qualifing the predicate
in question, for example "maybe", "on tuesdays", etc. (Table
ref:tbl:qa-ex, last two rows).  In this instance |A = Prop -> Prop|.

# NEGATIVE QUESTIONS
One complication are polar questions phrased in the negative
cite:cooper2012negative; for example: "Doesn't John like Bananas?".

In this instance, a simple a simple "no" answer can be ambiguous, and
a possible model would be a multi-valued kind of answer ("yes he does
" represented as |DefiniteYes|; "no he doesn't", represented
as |DefiniteNo|, "no" as |AmbiguousNo| / "He does in the weekend"
-> |Qualifier OnWeekend|:

#+begin_code
Q Multi ( \x. case x of
    AmbiguousNo -> Trivial
    DefiniteNo -> not (Like John Bananas)
    DefiniteYes -> Like John Bananas
    Qualifier m -> m (Like John Bananas)
  )
#+end_code

To represent ambiguity in the case of |AmbiguousNo|, we make the
answer provide no information, in the form of a trivial proposition
(which is always true regardless of context).

One potentially surprising feature is that, in our account, the
meaning of simple answers (such as "no") depend on the
context. However, we do not see this as a problem: indeed, the meaning
of short answers is /always/ context-dependent. (For example "Paris" has
a does not mean the same thing in the context of "Where do you live?"
as in the context "Where were you born?".)

Additionally, in the framework of a full dialogue management system,
the |AmbiguousNo| case should be treated as unresolving (the question
effectively remains unanswered). However, in such a framework, it is
always possible to receive a biasing answer ("I don't know") or no
answer whatsoever --- but we leave this out of scope of our analysis.

Yet even more complications are possible, by introduction of cases
such as rhethorical and attitudinal questions ("Do you know who I met
yesterday?"), which are also out of scope.


\begin{sidewaystable} %[htbp]
\begin{tabular}{lllll}
utterance & A & P & a\\
\hline
Where does John live?    & |Location    | & |\x.Live John x                          | & in London & |ShortAnswer Location London| \\
Does John live in Paris? & |Bool        | & \makecell[l]{|\x.if x then (Live John Paris)| \\ |else Not (Live John Paris)|} & yes & |ShortAnswer Bool True| \\
What time is it?         & |Time        | & |\x.IsTime x                             | & It is 5am. & |Assert (IsTime 5.00)| \\\hline
Does John live in Paris? & |Prop -> Prop| & |\m. m (Live John Paris)                 | & yes & |ShortAnswer  (Prop -> Prop) (\x. x)| \\
Does John live in Paris? & |Prop -> Prop| & |\m. m (Live John Paris)                 | & from January & \makecell[l]{|ShortAnswer (Prop -> Prop)|\\|(\x. FromJanuary(x))|} \\
\end{tabular}
\caption{Examples of questions and the possible corresponding answers.\label{tbl:qa-ex}}
\end{sidewaystable}

Within the state of the agent, if the value of the requested answer is
represented as a metavariable |x|, then the question can be
represented as: |Q A x (P x)|.  That is, the pending question is a
triple of a type, a metavariable |x|, and a proposition where |x|
occurs. We stress that |P x| is /not/ part of the information state of the
agent yet, rather the fact that the above question is /under
discussion/ is a fact. For example, after asking "Where does John
live", we have:

#+BEGIN_code
haveQud : QUD (Q Location x (Live John x))
#+END_code

Resolving a question can be done by communicating an answer. An answer
to a question |(A : Type; P : A -> Prop)| can be of either of the two following forms: 
1) A *ShortAnswer* is a pair of an element |X:A| and its type |A|,
   represented as |ShortAnswer A X|
2) An *Assertion* is a proposition |Q : Prop|, represented as |Assert Q|



Therefore, one way to process a short answer is by the |processShort| rule:

#+BEGIN_code
processShort :  (a : Type) -> (x : a) -> (p : Prop) -> 
                ShortAnswer a x ⊸ QUD (Q a x p) ⊸ p
#+END_code
Above we use Π type binders to declare metavariables (Written here |(a : Type)
->|, |(x : a) ->|, etc.). This terminology will make sense to readers
familiar with dependent types. For the others, such binders can be thought
as universal quantification (|∀ a, ∀ x|, etc.), the difference is that
the type of the bound variable is specified.

We demand in particular that types in the answer and in the question
match (|a| occurs in both places). Additionally, because |x| occurs
in |p|, the information state will mention the concrete |x| which was
provided in the answer.  For example, if the QUD was |(Q Location x
(Live John x))| and the system processes the answer |ShortAnswer
Location Paris|, then |x| unifies with |Paris|, and the new state will
include:
#+begin_code
Live John Paris
#+end_code

To process assertions, we can use the following rule:

#+BEGIN_code
processAssert :  (a : Type) -> (x : a) -> (p : Prop) ->
                 Assert p ⊸ QUD (Q a x p) ⊸ p
#+END_code

That is, if (1) |p| was asserted, and (2) the proposition |q| is part
of a question under discussion, and (3) |p| can be unified with |q|
(we ensure this unification by simply using the same metavariable |p|
in both roles in the above rule), then the assertion resolves the
question. Additionally, the metavariable |x| is ground to a value
provided by |p|, by virtue of unification of |p| and |q|. For example,
"John lives in Paris" answers both questions "Where does John live"
and "Does John live in Paris" (there is unification), but, not, for
example "What time is it?" (there is no unification).

Note that, in both cases (|processAssert| and |processShort|), the
information state is updated with the proposition posed in the
question. 

** Notion of unique and concrete values label:sec:unique-concrete

However, one should consider the question resolved only if the answer
is "unique". For example, the assertion "John lives somewhere" does
not resolve the question "where does John live". That is, if
"somewhere" is represented by a metavariable, then the answer is not
resolving.

Assume a two-place predicate |Eat| with agent as first argument and
object as second argument. The phrase "John eats Mars" could then
be represented as |Eat(John,Mars)|. According to our theory, one can
then represent the phrase "John eats" as |Eat(John,x)|, with |x| being
a metavariable.

Assume now a system with the following state:

#+BEGIN_code
Eat(John,Mars)
#+END_code

Then the question "What does John eat", represented as |(Q Food x
(Eat(John,x)))|, can be answered.  From the point of view of modelling
with linear logic, we could attempt to model the answering by the
rule as follows:

#+BEGIN_code
(a : Type) -> (x : a) -> (p : Prop) -> 
  QUD (Q a x p) -> p ⊸ (p ⊗ Answer x (Q x p))
#+END_code
Note: taking a linear argument and producing it again is a common
pattern, which can be spelled out |A ⊸ (A ⊗ P)|. It is so common that
from here on we use the syntactic sugar |A -* P| for it, so the above rule will be written:
#+BEGIN_code
(a : Type) -> (x : a) -> (p : Prop) -> 
  QUD (Q a x p) -> p -* Answer x (Q x p)
#+END_code

The above states that if |x| makes the proposition |p| true (more
precisely, provable --- we require that |p| is a fact in the last
argument) then it is valid to answer |x| if |Q a x p| is under
discussion. However, there is an issue with the above rule: there are
several values making |p| true, i.e. if |x| is /not unique/, then
intuitively one would not consider $x$ a suitable answer. Indeed,
assume instead that the system is in the state:

#+BEGIN_code
Eat(John,x)
#+END_code

Then the question cannot be answered, because |x| stands for some
unknown thing. The proper answer is then "I do not know".

Hence, we introduce another type-former |(x : A) !-> B|. As for |(x :
A) -> B|, it introduces the metavariable |x|. However, the rule fires
only when |x| is made /ground/ (it is bound to a term which does not
contain any metavariable) and /unique/ by matching the rule --- this is what we call a unique and concrete value. That is,
it won't match in the previous example, because the answer is not
ground (it contains unknowns). Additionally, it won't match if the
state of the system is composed of the two
hypotheses |Eat(John,Mars)| and |Eat(John,Twix)|: the answer is not
unique.

Thus, the rule for answering can be written like so:
#+BEGIN_code
produceAnswer : (a : Type) -> (x : a) !-> (p : Prop)
-> QUD (Q a x p) -> p -* ShortAnswer a x
#+END_code

For example, if we have the following state:
#+BEGIN_code
QUD (Q Food x (Eat(John,x)))
Eat(John,Mars)
#+END_code

The system can unify |QUD (Q Food x (Eat(John,x)))| and |QUD (Q a x
p)|, yielding |a = Food| and |p=Eat(John,x)|. Then, we search for a
proof |p|, and to do this, we can unify |Eat(John,x)|
with |Eat(John,Mars)|, giving finally the answer |x=Mars| and
therefore the state becomes:
#+BEGIN_code
Eat(John,Mars)
ShortAnswer Food Mars
#+END_code

Note that the fact |Eat(John,Mars)| is found both as hypothesis and a
conclusion of |produceAnswer|, and therefore it is remains in the
information state.

** Clarification requests and follow-up questions label:sec:cr

In this section we discuss an alternative kind of answering, which is
to issue clarification requests.  To see how they can occur, consider
again the question "what does john eat", in the same information state
as above.  A proper answer could be "Mars and Twix" or even "Mars or
Twix". However we consider here a third possibility: instead of
answering, the agent can issue a clarification request.

To illustrate, consider the question "What is being eaten?"
represented as |Q x (Eat(y,x))|,  with the state
#+BEGIN_code
Eat(John,Mars)
Eat(Mary,Mars)
#+END_code
Then the agent can unambguously answer "Mars": even if we do not
know who we're talking about, it does not matter: only Mars is
being eaten. However, If the state is
#+BEGIN_code
Eat(John,Mars)
Eat(Mary,Twix)
#+END_code
Then, a probable answer would be a /clarification request/, namely
"By whom?".

To detect situations where a clarification request can be issued, we can use the following rule:
#+BEGIN_code
[a : Type;
 x : a; 
 p : Prop;
 havePAsQud :: QUD (Q x p);
 proof :: p] ?-> CR
#+END_code
(We leave the exact form of the CR abstract for now and come back to it below)

The conditions are similar to that of the answering rule. The
principal difference is the use of the |?->| operator, which takes as
left operand the specification of a request and test for it to have a
non-unique solution or it be not (fully) made ground. Essentially this
does the the opposite of the |!->| operator.  However, because the
components of the query are indeterminate, they cannot be fixed when firing the rule,
and therefore the state update cannot depend on them. Therefore we use the record
syntax to bound their scope, ensuring that they won't occur in the state update. Additionally, note the use of the single
colon (|:|) for metavariables and the double colon for
information-state hypotheses (|::|).

We can then turn our attention to the formulation of this clarification request.
It is itself a question, and has a tricky representation:

#+BEGIN_code
Q Person z (z = y)
#+END_code

That is, the question is asking about some aspect which was left
implicit in the original question (what is being eaten). In our terms,
it must refer to the metavariable (|y|) which the original
question included.  After getting an answer, (say |Mary|), |z|
will be bound to a ground term, and, in turn, the fact |z=y| will
ensure that |y| becomes ground. 

#+BEGIN_code
Eat(John,Mars)
Eat(Mary,Twix)
ori  ::  QUD (Q Food x (Eat(y,x)))
cr   ::  QUD (Q Person z (z=y))
a    ::  ShortAnswer Person Mary
#+END_code
after applying |processShort|:
#+BEGIN_code
Eat(John,Mars)
Eat(Mary,Twix)
ori  :: QUD (Q Food x (Eat(y,x)))
r    ::  Mary=y
#+END_code


This means the original question will, by unification, become |Q Food
x (Eat(Mary,x))|, and it can be unambiguously answered using
the |produceAnswer| rule. We note that the logical form of the
question ( |z| such that |z=y|) is typically realised in a complicated
way. In our example, it could be "By whom"; echoing part of the
original question and assuming cooperative communication so that the
questioner properly relates the clarification request to the implicits
of the original questions.

In practice, the form of clarification questions will greatly vary
depending on the context.

The above suposes a clear-cut distinction: if an answer is unique, it
is given; otherwise a clarification request is issued. However,
answers could simply be exhaustive ("Mars or Twix").  If the
original questioners are unhappy with the ambiguity, they are free to
issue more precise questions. In practice, one can easily imagine an
ambiguity threshold after which clarification requests are
preferred. In the simplest form, this ambiguity threshold could be
expressed by the length of the answer. In our example, if one has to
list, say, 20 different kinds of food, it is easy to imagine that the
answer won't be fully given. In fact, this question can be the topic
of an experimental study.


*** Clarification via adding extra arguments

The scope of what is subject to clarification is anything which can be
represented as an argument in a relation.
For instance, consider the polar question "Where does John live?". The
questionee may decide that there is some ambiguity about /which/ Paris
one is talking about --- after all there are several places with this name. 
To be able to model this, the |Live| relation needs to be
generalised to be a 3-place predicate, where the country is specified.

However most of the time one may choose to leave this parameter
implicit. This is what is done for example when asking the above
question:

#+BEGIN_code
Q Location x Live(John,x,y)
#+END_code

If the question can be answered without regard for the country, then
the metavariable will remain free for the duration of the dialogue. If
on the other hand, answering the question demands clarification, this
can be done using the mechanisms described above.
In sum, in our model, to support clarification requests, a system must
integrate many arguments and use metavariables.

The same technique can apply to polar questions. Considering "Does John live in Paris?",
we can assume that the question can be encoded (for simplicity)
as |\x. if x then (Live John Paris y) else Not (Live John Paris y)|.

If the system has the following facts:
#+begin_code
Live John Paris France
Not (Live John Paris Denmark)
#+end_code
then both "True" and "False" are valid answers, and a clarification
requests should be issued: |Q Country z (z=y)|. We see again that the
realisation of the clarification request depends highly on the
formulation of the question and the context. In this case "Do you mean
Paris, France?"  would be suitable.

*** Clarification via adding named contextual parameters
The above presentation (using a ternary predicate) is useful
conceptually, but not ideal in practice: in the most general case one
would end-up with predicates with lots of arguments, for example
country, county, district, etc.

However, there is a standard solution to the issue: because the
country is functionally dependent on the location, these two concepts
should be linked directly together rather than involve the |Live|
predicate. Using an intermediary entity type for locations and binary
predicates, one can represent the question "Does John live in Paris?"
as follows: |\x. if x then (Live John y -> Name y Paris) else Not
(Live John y -> Name y Paris) |

Literally, "Does John live in a place called Paris?".

The ambiguity of the |Paris| name can be represented by several
locations named |Paris|, |X| and |Y| in our illustration:
#+begin_code
Name Paris X
Name Paris Y
Live John X
Not (Live John Y)
Country France X
Not (Country France Y)
#+end_code

Because John lives in |X| but not in |Y| the question is
ambiguous. One way to lift the ambiguity is raise the clarification
request as above. Here it can be phrased as a polar question[fn::Here
we use the simpler version of the treatment of polar questions.]
again: |Q Bool (\x. if x then Country France y else Not (Country
France y))|


*** Summary

In sum, we leverage a feature of linear-logic proof search: at any
point in the scenario, the context can refer to metavariables.

In a dialogue application, metavariables represent a certain amount of
flexibility in the scenario: /so far/ the scenario works for any value
which could be assigned to the metavariable. This means that at a
further point the metavariable can be instanciated to some other
value. 

* Kos-inspired dialogue management with linear logic
label:sec:dm

In this section we integrate our question/answering framework in a
more complete dialog manager (DM).  We stress that this DM models the
information-state of only one participant. Regardless, this
participant can record its own beliefs about the state of other
participants. Figure ref:fig:ds shows how such a DM can be integrated
into a spoken dialogue system. In general, the core of DM is comprised
of a set of linear-logic rules which depend on the domain of
application. However, many rules will be domain-independent (such as
generic processing of answers). We show these generic rules first, and
then illustrate them with an example application.


\begin{figure}
\centering
\begin{tikzpicture}[auto, node distance=2.2cm]

    \node [block]                 (input)     {Knowledge Base};
    \node [block, below of=input]   (tc)     {Type Checker};
    \node [block, below of=tc] (appl)    {Rule application};
    \node [block, below of=appl, align=center] (sub)    {Information state:\\ \emph{linear propositions}};
    \node [virtual, below of=tc] (feedback)  {};
    
    \node [block, fit={(appl) (sub)}, align=left,
           rounded corners, inner sep=8pt] (dm) {DM};
           
	\node at (5cm, -4cm) [block, rounded corners] (nlu) {NLU and ASR};
    \node at (5cm, -7cm) [block, rounded corners] (nlg) {NLG and TTS};
    \node at (8cm, -5.5cm) [inner sep=5pt, align=center] (user)
    {\Huge\smiley\normalsize\\user};
    % Connect nodes
    \draw [->] (input) -- node {rules} (tc);
    \draw [->] (tc) -- node {verified rules} (appl);
    \draw [<->] (appl) -- node {} (sub);
    \draw [->] (nlu) -- node {user moves} (dm);
    \draw [->] (dm) -- node {agent moves} (nlg);
    \draw [->] (user) -- node {} (nlu);
    \draw [<-] (user) -- node {} (nlg);
    %\draw [->] (model) -- node [name=y] {$y$}(output);
    %\draw [->] (y) |- (feedback);
\end{tikzpicture}
\caption{Architecture of a spoken dialogue system with a dialogue manager based on linear logic framework.}
\label{fig:ds}
\end{figure}

** Domain-independent rules
*** Interface with language understanding and generation
To be useful, a DM must interact with the outside world, and this
interaction cannot be represented using logical rules, which can only
manipulate data which is already integrated in the information state.
Here, we assume that the information that comes from sources which are
external to the dialogue manager is expressed in terms of semantic
interpretations of moves, and contains information about the speaker
and the addressee in a structured way. We provide 5 basic types
of moves as an illustration:
#+BEGIN_code
Greet         spkr  addr
CounterGreet  spkr  addr
Ask           question  spkr  addr
ShortAnswer   vtype v spkr  addr
Assert        p  spkr  addr
#+END_code

These moves can either be received as input or produced as outputs. If
they are inputs, they come from the NLU component, and they enter the
context with |Heard : Move -> Prop| predicate. For example, if one
hears a greeting, the proposition |Heard (Greet S A)| is added to the
information state/context, without any rule being fired --- this is
what we mean by an external source.


If they are outputs, to be further used by the NLG component, some
rule will place them in |Agenda|. For example, to issue a
countergreeting, a rule will place the proposition |Agenda
(CounterGreet A S)| in the information state.

Thereby each move is accompanied by the information
about who has uttered it, and towards whom was it addressed. All the
moves are recored in the |Moves| part of the participant’s dialogue
gameboard, as a |Cons|-list (stack).

Additionally, we record any move |m| which one has yet to actively
react to, in an hypothesis of the form |Pending m|. We cannot use the |Moves|
part of the state for this purpose, because it is meant to be static
(not to be consumed). |Pending| thus allows to make the difference
between a move which is fully processed and a pending one.

*** Initial state
In general, we start with empty |QUD| and |Agenda|. An non-empty |QUD|
can be prepared if, in a certain domain, some open questions are
assumed from the start. The |Agenda| might not be empty if one wants
the system to initiate the conversation. There are also no moves:
nothing has been said by neither party.

#+BEGIN_code
_ :: QUD Nil;
_ :: Agenda Nil;
_ :: Moves Nil;
#+END_code

(We often do not care about the proof object witnessing a propositions,
in which case we denote it with an underscore).

*** Hearing
The capacity of "hearing" or, in other words, starting the processing
of semantic representations of utterances from the NLU component, is
implemented with the following rule:
#+BEGIN_code
hearAndRemember  :
  (m : DP -> DP -> Move) -> (x y : DP) -> (ms : List Move) ->
  Heard (m x y)  ⊸
  Moves ms       ⊸
  HasTurn x      ⊸ [  _ :: Moves (Cons (m x y) ms);
                      _ :: Pending (m x y) ;
                      _ :: HasTurn y ];
#+END_code
where |(m x y)| is a semantic representation of the utterance. Here it
is assumed that participant |x| has the turn and, as a result, turn was
taken by their partner |y|[fn::For now we have a very simple model of turn-taking, which can be
improved in many ways: certain moves may not induce turn-change, there
can be more than two participants, etc.]. The |DP| type stands for /dialogue
participant/. As a result we do several things: i) place the move in a move
list for further references (|PushMove|), ii) record the
turn-switching (which in a complete system may not apply to all cases
--- then additional hypotheses would be added.), and iii) prepare to
process the move (|Pending|).

*** Uttering
The capacity of "uttering" represents an ability to generate
information for the NLG component. NLP component is represented
by |Agenda| that contains a move that is just about to be uttered.
#+BEGIN_code
utterAndRemember :
  (m : DP -> DP -> Move) -> (ms : List Move) -> (x y : DP) ->
  Agenda (m x y)  ⊸
  Moves ms        ⊸
  HasTurn x       ⊸ [  _ :: Utter (m x y);
                       _ :: Moves (Cons (m x y) ms);
                       _ :: HasTurn y];
#+END_code

Here also we take care of turn-taking in the same rule. As a result,
the system consumes the |Agenda| and passes the move to the NLG
component. The move is also memorised in the |Moves| stack.
*** Basic adjacency: greeting
We can show how basic move adjacency can be defined in the example of
countergreeting preconditioned by a greeting from the other party:
#+BEGIN_code
counterGreeting :  (x y : DP) -> 
                   HasTurn x            -*
                   Pending (Greet y x)  ⊸
                   Agenda (CounterGreet x y);
#+END_code
*** QUD incrementation
Another important rule accounts for pushing the content of the last move, in the case if it is an |Ask| move, on top of the questions under discussion (|QUD|) stack.

#+BEGIN_code
pushQUD :  (q : Question) -> (qs : List Question) ->
           (x y : DP)           -> 
           Pending (Ask q x y)  ⊸ 
           QUD qs               ⊸ 
           QUD (Cons q qs)
#+END_code
*** Integrating the answers
If the user asserts something that relates to the top |QUD|, then
the |QUD| can be resolved and therefore removed from the stack. The
corresponding proposition |p| is saved as a |UserFact|[fn::For the
current purposes we only remove the top QUD, but in a more general
case we can implement the policy that can potentially resolve any QUD
from the stack.]. This rule extends the abstract rule that were
introduced in section ref:sec:cr.
#+BEGIN_code
processAssert : (a : Type) -> (x : a) ->  (p : Prop) -> 
  (qs : List Question) -> (dp dp1 : DP) ->
  Pending (Assert p dp1 dp)          ⊸ 
  QUD (Cons (Question dp a x p) qs)  ⊸ [  _ :: UserFact p;
                                          _ :: QUD qs];
#+END_code

Short answers are processed in a very similar way to assertions:
#+BEGIN_code
processShort : (a : Type) -> (x : a) ->  (p : Prop) -> 
  (qs : List Question) -> (dp dp1 : DP) ->
  Pending (ShortAnswer a x dp1 dp)   ⊸ 
  QUD (Cons (Question dp a x p) qs)  ⊸ [  _ :: UserFact p;
                                          _ :: QUD qs];
#+END_code

*** Questions and clarifications
Just as we described in ref:sec:unique-concrete, we use uniqueness check to determine
whether system can resolve the question (|produceAnswer|) or it needs
to initiate a clarifying side sequence (|produceCR|).

#+BEGIN_code
produceAnswer :
   (a : Type)            ->
   (x : a)               !->
   (p : Prop)            ->
   (qs : List Question)  ->	
   QUD (Cons (Question USER a x p) qs)  ⊸
   p  -*
   [  _ :: Agenda (ShortAnswer a x SYSTEM USER);
      _ :: QUD qs;
      _ :: Answered (Question USER a x p)];
#+END_code
#+BEGIN_code
produceCR :
   [  a : Type ;
      x : a ;
      p : Prop ;
      qs : List Question ;
      _  :: QUD (Cons (Question USER a x p) qs) ;
      _  :: p   ] ?-> CR;
#+END_code

The clarifying side sequence itself (|CR|) is meant to be specified by
a dialogue developer, possibly informed by machine-learning systems,
because it is domain-specific and the choice of the spectrum of
possible options is wide. We provide an example of a
domain-specific |CR| in the section ref:sec:example below.

** Example label:sec:example
We now turn to how the generic system of rules above can handle the following exchange:
#+begin_quote
U: Hello!\\
S: Hello, USER.\\
U: When there is a bus from Gotaplatsen?\\
S: In 15 minutes.
#+end_quote

Let us further assume the following system context, which contains
up-to-date public transport information (we just give a few
examples, |kbX| for "knowledge base").
#+BEGIN_code
TT B18 T15   Gotaplatsen     Johanneberg
TT B55 T20   Gotaplatsen     SciencePark
#+END_code
They are added to the initial domain-independent context
outlined above. We also assume that the user has the turn at the start. 
#+BEGIN_code
QUD      Nil
Agenda   Nil
HasTurn  USER
Moves    Nil
#+END_code

The when the systems hears the greeting it can be integrated into
the state using |hearAndRemember| rule, therefore system updates its
state accordingly:
#+BEGIN_code
QUD      Nil
Agenda   Nil
HasTurn  SYSTEM
Moves    [ Greet USER SYSTEM ]
#+END_code

In this context the system can issue a countergreeting by firing
the |counterGreeting| rule:

#+BEGIN_code
Agenda   (CounterGreet SYSTEM USER)
HasTurn  SYSTEM
Moves    [ Greet USER SYSTEM ]
#+END_code

Everything which is on the agenda can be uttered
using |utterAndRemember| rule, given that the system has the
turn. System also hands the turn over to the user. Therefore, the
state becomes:

#+BEGIN_code
HasTurn USER
Moves
[  CounterGreet  SYSTEM USER   
   Greet         USER SYSTEM         ]
#+END_code
(we use bracket syntax instead of |Cons| for readability)

Now the systems hears the question (|Ask| move: |(Ask (Question t (TT
n t Gotaplatsen d)))|. It is domain specific, and basically requests
the timetable information for the given departure station. Again, we
use |hearAndRemember| rule to itegrate it into state, but also,
because the move is |Ask|, the system sets its QUD to the question that
the move contains with the |pushQUD| rule. 

#+BEGIN_code
QUD [  Question USER Time t0 (TT n0 t0 Gotaplatsen d0)  ]
HasTurn SYSTEM
Moves
[  Ask (Question USER Time t0 (TT n0 t0 Gotaplatsen d0)) USER SYSTEM
   CounterGreet  SYSTEM USER
   Greet         USER SYSTEM  ]
#+END_code

Now, depending on the state of the knowledge base, the system will
have two options: i) produce the answer straight away, or ii)
integrate a clarifying side sequence.
*** Straight answer
For this case we will consider a knowledge base that includes
information just about the unique (w.r.t. the time) entry in the
timetable:
#+BEGIN_code
TT B18 T15   Gotaplatsen     Johanneberg
#+END_code

Therefore the question can be resolved and the resolving short answer
can be put on the |Agenda|.
#+BEGIN_code
Answered (Question  USER Time T15
                    (TT B18 T15 Gotaplatsen Johanneberg))
QUD Nil
HasTurn SYSTEM
Agenda (ShortAnswer Time T15 SYSTEM USER)
Moves  […] -- same as above
#+END_code
*** Clarifying side sequence
In contrast, we can extend our minimal timetable example with another entry,
therefore making it non-unique, w.r.t. time. 
#+BEGIN_code
TT B18 T15   Gotaplatsen     Johanneberg
TT B55 T20   Gotaplatsen     SciencePark
#+END_code

In order to make it unique we can either clarify the bus number or the
destination. We decided to go with the bus number here, and the rule
for clarification can be formulated as follows:
#+BEGIN_code
specificCR :
  (t : Time) -> (n : Bus) -> (s d : Location) ->
  (qs : List Question) ->
  CR ⊸
  QUD (Cons (Question USER Time t  (TT n t s d))  qs)   ⊸
  [  _ :: QUD (Cons  (Question SYSTEM Bus n (WantBus n)) 
                   (Cons (Question USER Time t (TT n t s d)) qs));
     _ :: Agenda (Ask  (Question SYSTEM Bus n (WantBus n))
                     SYSTEM USER) ];
#+END_code

As a result of applying it, the state becomes:
#+BEGIN_code
Agenda (Ask (Question SYSTEM Bus n0 (WantBus n0)) SYSTEM USER)
QUD
     [  Question SYSTEM Bus n0 (WantBus n0)
        Question USER Time t0 (TT n0 t0 Gotaplatsen d0) ]
HasTurn SYSTEM  
Moves […]  -- same as above
#+END_code

Then, the system can utter the clarification request (|utterAndRemember| rule): 
#+BEGIN_code
QUD  [  Question SYSTEM Bus n0 (WantBus n0)
        Question USER Time t0 (TT n0 t0 Gotaplatsen d0) ]
HasTurn SYSTEM  
Moves  [  Ask (Question SYSTEM Bus n0 (WantBus n0)) SYSTEM USER
          Ask (Question USER Time t0 (TT n0 t0 Gotaplatsen d0)) USER SYSTEM
          CounterGreet SYSTEM USER
          Greet USER SYSTEM  ]
#+END_code

The user can reply to this with a short answer |(ShortAnswer Bus B55)| or
an assertion |(Assert (WantBus B55)|, which can be integrated
using |processShort| or |processAssert| rule correspondingly. Here we
show the state after processing the short answer.
#+BEGIN_code
QUD  [  Question USER Time t0 (TT B55 t0 Gotaplatsen d0) ]
UserFact (WantBus B55)
HasTurn SYSTEM
Moves  [  ShortAnswer Bus B55 USER SYSTEM
          Ask (Question SYSTEM Bus B55 (WantBus B55)) SYSTEM USER
          …  ]
#+END_code
The reader can notice that the metavariable |n0| from the previous
state is now unified with |B55| in the question under discussion,
therefore it now corresponds to one unique entry in the knowledge
base. Hence, the answer can be issued, by the |produceAnswer| rule.

#+BEGIN_code
Answered (Question  USER Time T20
                    (TT B55 T20 Gotaplatsen SciencePark))
QUD Nil
Agenda (ShortAnswer Time T20 SYSTEM USER)
UserFact (WantBus B55)
HasTurn SYSTEM
Moves […]  -- same as above
#+END_code

label:sec:kos

* Related work
label:sec:related

In this work we provide a minimal and granular account for
clarification requests initiated by any conversational party,
following accounts of and supporting a subset of cases that were
thoroughly investigated in a CLARIE Prolog-based system
citep:purver-rlc06, following corpus studies by citet:purver2003means
and citet:rodriguez2004form.

** KoS

One of our main sources of inspiration is Ginzburg's KoS
cite:ginzburg2012interactive. However we recast it in the framework of
proof search, and linear logic. We have argued that this has many
advantages. First, it affords the use of metavariables to represent
uncertaintly, which is absent from TTR.  Second, expressing updates
using linear logic rules means that only the relevant parts of the
information state must be dealt with in any given rule. Cooper's TTR
has a special "assymetric merge" operator for this purpose, but it is
a less-studied \textit{ad-hoc} addition to type-theory.

Furthermore, as it stands, KoS is lacking implementations, with the
exception of the work of citet:maraev_kosttr-based_2018, who adapt KoS
to eschew the assymetric merge operation.  As we see it, this sparsity
of implementations is largely due to the semantic gap between its aims
(information-state dialogue management) and its formalism (TTR).

An oft-touted advantage of TTR is that propositions are witnessed by
proof objects. We benefit from the same advantage: we use an
intuitionistic system, and as such every proposition in the
information state is associated a witness, even if we have not shown
them for concision (they play little role in our analysis).

** Dialogue management

citet:larsson2000godis proposed the use of Prolog (and hence, proof
search), as a dialogue management framework. However, the lack of
linear hypotheses means that destructive information-state updates are
sometimes awkward to represent. Besides, they do not consider the use
of metavariables to represent uncertainty --- even though Prolog is in
principle has the capacity to do it.

To our knowledge citet:dixon2009plans were the first to advocate the
use of linear logic for dialogue management and planning. Compared to
the present work, they focus primarily on the planning part of
dialogue, rather than question-answering. In particular, they do not
discuss the role of metavariables and clarification requests.

We additionally propose the extension of linear logic with
special-purpose operators | X !-> Y | and | X ?-> Y | to distinguish
the presence or the absence of ambiguity.

* Evaluation/Discussion/Future work
label:sec:discussion

A kind of dialogue move often studied in parallel to clarifications
are /corrections/. It would be elegant if corrections could be
formalised in a way similar clarifications. However, in our analysis,
metavariables disappear once they have been grounded. Therefore,
corrections cannot involve metavariables and thus require a different
treatment. A solution could be to keep metavariables in terms (apply unification substitutions
lazily). We leave a detailed study to further work.

We note that the use of (meta)variables to refer to discourse objects
is a very general device. Anything which can be subject to
clarification can occur as an argument to predicates. We already
showed how "Paris" can be clarified. But we could also clarify "Live"
by making the verb be an argument to a general |Apply| predicate,
taking say a verb and its arguments.


Prior studies have noted the phenomenon of semantic dependency
relations between questions cite:wisniewski2015semantics, e.g. the
answer to "Who killed Bill?" can depend on the answer to "Who was in
town?". The cases of dependencies covered in this study are limited to
clarification of metavariables from the original question. This is
meant to serve as a proof-of-concept rather than thorough coverage of
all possible cases of question dependence. A similar issue concern
follow-up questions that are meant to clarify the type of the
metavariable, e.g. "What does John like? Do you mean
foodwise?". Generally, further work is needed to be carried out in
order to extend our system to full-scale coverage of interrelations
between QUDs.

A natural progression of this work is to allow the assignment of
probabilities to rules and to the components of the information state,
and to train the probabilities according to the new observations. In
this sense our approach follows citet:lison2015hybrid, which is based
on probabilistic rules, but in our case the structure of information
state is rich and derived from the theoretical outlook on dialogue,
and dialogue management has a core set of domain-independent rules.
We can also imagine combining such ideas with probabilistic meaning
for sentences
cite:goodman_probabilistic_2015,bernardy_compositional_2018.

TODO other limitations?
TODO briefly describe the evaluation benchmarks

Table ref:table:ds originates from cite:ginzburg-nlphandbook, who
proposed a series of benchmarks for comparing different approaches to
developing dialogue systems (see section xxx of that paper). For each
approach the symbol \checkmark indicates that the approach safisfies
the benchmark in the corresponding row; $\sim$ that the benchmark
could be met with some caveats, as explained in the text above; and
--- that the benchmark is not met by a standard version of the
approach. Here we discuss

\begin{table}
\centering
\begin{tabular}{lc}
\hline
{Benchmarks}                         & {Our system} \\\hline\hline
{\bf query and assertion}            & \\
Q1 simple answers                    & \checkmark \\
Q2a non-resolving answers            & \checkmark \\
Q2b follow up queries                & \checkmark \\
Q3 overinformative answers           & \checkmark \\
Q4 sub-questions                     & \checkmark \\
Q5 topic changing                    & \\
A1 propositional content update      & \checkmark \\
A2 disagreement                      & \\ 
SC scalability                       & $\sim$ \\
DA domain adaptability               & \checkmark \\ \hline
{\bf metacommunication}              & \\
Ack1 completed acknowledgements      & \\
Ack2 continuation acknowledgements   & \\
Ack3 gestural acknowledgements       & \\
CR1 repetition CRs                   & \\
CR2 confirmation CRs                 & \\
CR3 intended content CRs             & \checkmark \\
CR4 intention recognition CRs        & \\
SND distinct updates                 & $\sim$ \\
FG fine-grained representations      & $\sim$ \\ \hline
{\bf fragments}                      & \\
SF1 wide coverage of SFs             & $\sim$ \\
SF2 basic answer resolution          & $\sim$ \\
SF3 reprise fragment resolution      & \\
SF4 long distance short answers      & \\
SF5 genre sensitive initiating SFs   & \\
D1 recognize and repair disfluencies & \\
D2 keep disfluencies in context      & \\\hline
\end{tabular}\caption{System evaluation}
\label{table:ds}
\end{table}


\bibliography{tal}

* COMMENT references
bibliography:tal.bib



# Local Variables:
# org-latex-subtitle-separate: t
# org-latex-classes: (("article-hermes_french" "\\documentclass[english,utf8]{article-hermes_french} " ("\\section{%s}" . "\\section*{%s}") ("\\subsection{%s}" . "\\subsection*{%s}")("\\subsubsection{%s}" . "\\subsubsection*{%s}") ("\\paragraph{%s}" . "\\paragraph*{%s}") ("\\subparagraph{%s}" . "\\subparagraph*{%s}")))
# End:

* COMMENT notes 

** VM & JG <2020-06-12 Fri>
Why should we care? 
- one of the ideas is to deal with structured NLU representations
- repair is a minor issue
- reach coherence, and some responses have low frequency, therefore it
  is hard to learn them from data

How is it better than other systems?
- Traum: ICT systems, sensai, psychotheraphy consulting
- TDM
- end2end, as they referee sigdial/acl
- Young et al.
- Sadek, Phil Colin

More punch: either benefit for semantic theories, or to dialogue system building.

+ Shalom’s point from Friday: formal systems as reality/sanity check,
  can be used to highlight linguistic phenomena and relations between
  them. A source of insight for improving deep learning systems.

** <2020-06-22 Mon>
discussion:
- need story/footnote/discussion about binding vs. metavariables in
  order to suppost embedded questions (limitations)
- how do we scale-up?

introduction:
- some story about granularity, that we can scale up for fully
  implemented dialogue theory

evaluation:
- notion of benchmarks, like GoDIS ticklist (fernandes&ginzubrg 2010)

** questions <2020-06-26 Fri>
- how bools are unified with assertions
- concrete answers - what are these?
- should we have ∀ everywhere?

* COMMENT Attic

As an example, we can show how the rule for /QUD-incrementation/ from
cite:ginzburg2012interactive can be formulated in this terms. Here
we consider the dialogue between interlocutors /A/ and /B/, when /A/ asks
/B/[fn::Here we omit addressees as the conversation is only two-party.]
a question /Q/. The question /Q/ just have been posed and therefore has
appeared on the DGBs of both /A/ and /B/ as the latest ~Ask~ move
(~LatestMove~).
#+BEGIN_SRC sh :exports code
-- context
_ :: DGB A (LatestMove (Ask A Q));
_ :: DGB B (LatestMove (Ask A Q));
#+END_SRC

Now we can define our update rule that act on the contextual resources:
#+BEGIN_SRC
_ : (q : Question) -> (x y : User) ->
    DGB x (LatestMove (Ask y q)) ⊸ DGB x (QUD q);
#+END_SRC
Here, for any interlocutor, her ~LatestMove~ asking a question is
consumed and her ~QUD~ is updated with the question from the ~Ask~ move.

** Not explained in the text

Does John live in Paris? & \makecell[l]{|QuestionPolarity ->|\\|Prop -> Prop|} & |\m. m Positive (Live John Paris)| & yes & |ShortAnswer  (Prop -> Prop) (\x. x)| \\
Doesn't John live in Paris? & \makecell[l]{|QuestionPolarity ->|\\|Prop -> Prop|} & |\m. m Negative (Live John Paris)| & no / oui &

\begin{minipage}{3cm}
\begin{code}
ShortAnswer (\ pol prop .
  if   Positive then Not prop
  else prop) (Prop -> Prop)
\end{code}
\end{minipage}\\
Doesn't John live in Paris? & \makecell[l]{|QuestionPolarity ->|\\|Prop -> Prop|} & |\m. m Negative (Live John Paris)| & si &
\begin{minipage}{3cm}
\begin{code}
ShortAnswer (\ pol prop . 
  if   Positive then ERROR 
  else Not prop) (Prop -> Prop)
        \end{code}
\end{minipage}\\
\end{tabular}
